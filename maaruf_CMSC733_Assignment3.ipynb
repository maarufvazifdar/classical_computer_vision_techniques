{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/maarufvazifdar/cmsc733/blob/main/maaruf_CMSC733_Assignment3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Assignment 3: \n",
        "\n",
        "Name: \n",
        "\n",
        "UID:\n",
        "\n",
        "Please submit to ELMS\n",
        "- a PDF containing all outputs (by executing **Run all**)\n",
        "- your ipynb notebook containing all the code\n",
        "\n",
        "I understand the policy on academic integraty (collaboration and the use of online material).\n",
        "Please sign your name here: "
      ],
      "metadata": {
        "id": "flVP-gDsfegx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Import necessary libraries here (You can add libraries you want to use here)\n",
        "import os\n",
        "import random\n",
        "import cv2\n",
        "import numpy as np\n",
        "from scipy.io import loadmat\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import cm\n",
        "%matplotlib inline"
      ],
      "metadata": {
        "id": "Cee3vAcLrOs0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Part 1: Epipolar Geometry (30 Points)\n"
      ],
      "metadata": {
        "id": "f3j4FysdrPpj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Overview\n",
        "\n",
        "In this problem, you will implement an algorithm for automatically estimating homography with RANSAC. In the file matches.mat, we provide the detected Harris corners row-column positions in variables r1 c1 for the first image; variables r2 c2 for the second image; and the corresponding matched pairs in the variable matches.\n",
        "\n",
        "<!-- <img src=\"https://drive.google.com/uc?id=1Tr723u5OXmwkd4RDmu9z886ITJU9j1cL&export=download\" width=\"800\"/> -->\n",
        "\n",
        "<img src=\"https://drive.google.com/uc?id=17mwO8QH24vw1Kv1aBONgFXKi53HqUMEd&export=download\" width=\"800\"/>\n",
        "\n",
        "\n",
        "The outline of the normalized 8-point algorithm:\n",
        "\n",
        "<img src=\"https://drive.google.com/uc?id=1nVnvBpKeLmiowT9Q4_QauogXpcdXBmHm&export=download\" width=\"700\"/>\n",
        "\n"
      ],
      "metadata": {
        "id": "-PQh0Alx6ibx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data\n",
        "\n",
        "**WARNING: Colab deletes all files everytime runtime is disconnected. Make sure to re-download the inputs when it happens.**"
      ],
      "metadata": {
        "id": "WhMdiMNjB9R7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Download Data -- run this cell only one time per runtime\n",
        "!gdown 1cn3_SscjlLrf4BzUWe8MV-XqMqBY4Nj_\n",
        "!unzip \"/content/Part1_data.zip\" -d \"/content/\"\n",
        "# Load Matches\n",
        "data = loadmat('/content/Part1_data/matches.mat')\n",
        "r1 = data['r1']\n",
        "r2 = data['r2']\n",
        "c1 = data['c1']\n",
        "c2 = data['c2']\n",
        "matches = data['matches']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3LNhf2S4CAIk",
        "outputId": "4d803bc7-42c4-436e-f721-c7f4d085d54a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1cn3_SscjlLrf4BzUWe8MV-XqMqBY4Nj_\n",
            "To: /content/Part1_data.zip\n",
            "\r  0% 0.00/157k [00:00<?, ?B/s]\r100% 157k/157k [00:00<00:00, 62.2MB/s]\n",
            "Archive:  /content/Part1_data.zip\n",
            "   creating: /content/Part1_data/\n",
            "  inflating: /content/Part1_data/chapel00.png  \n",
            "  inflating: /content/Part1_data/chapel01.png  \n",
            "  inflating: /content/Part1_data/matches.mat  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load Keypoints\n",
        "x1 = c1[matches[:,0]-1]\n",
        "y1 = r1[matches[:,0]-1]\n",
        "x2 = c2[matches[:,1]-1]\n",
        "y2 = r2[matches[:,1]-1]"
      ],
      "metadata": {
        "id": "7JTA_rZ4y_V8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Helper Functions"
      ],
      "metadata": {
        "id": "QyGOs95Bslvr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.ndimage import gaussian_filter as gf\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "def show_image(img, scale=1.0):\n",
        "    plt.figure(figsize=scale* plt.figaspect(1))\n",
        "    plt.imshow(img, interpolation='nearest')\n",
        "    plt.gray() \n",
        "    plt.axis('off')\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "UkmZo6KWslNG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Code (15 pt)"
      ],
      "metadata": {
        "id": "JjIGNyapNU_4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def ransacF(x1, y1, x2, y2):\n",
        "  # Find normalization matrix\n",
        "  # Transform point set 1 and 2\n",
        "  # RANSAC based 8-point algorithm\n",
        "  # YOUR CODE HERE: \n",
        "\n",
        "  return None\n",
        "\n",
        "def getInliers(pt1, pt2, F, thresh):\n",
        "  # Function: implement the criteria checking inliers. \n",
        "  # YOUR CODE HERE:\n",
        "\n",
        "  return None\n",
        "\n",
        "\n",
        "def normalize(x, y):\n",
        "  # Function: find the transformation to make it zero mean and the variance as sqrt(2)\n",
        "  # YOUR CODE HERE: \n",
        "  \n",
        "  return None\n",
        "\n",
        "  \n",
        "def computeF(x1, y1, x2, y2):\n",
        "  #  Function: compute fundamental matrix from corresponding points\n",
        "  # YOUR CODE HERE: \n",
        "  \n",
        "  return None\n",
        "\n"
      ],
      "metadata": {
        "id": "lS5zihq7NRjh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Write-up (15 pt)\n",
        "*   Describe what test you used for deciding inlier vs. outlier.\n",
        "*   Display the estimated fundamental matrix F after normalizing to unit length\n",
        "*   Randomly select 7 sets of matching points. Plot the corresponding epipolar lines and the points on each image. Show the two images (with plotted points and lines) next to each other.\n",
        "\n",
        "<!-- *   Plot the outlier keypoints with green dots on top of the first image -->\n",
        "<!-- *   Randomly select 7 sets of matching points. Plot the corresponding epipolar lines ('g’) and the points (with 'r+’) on each image. Show the two images (with plotted points and lines) next to each other. -->\n",
        "\n"
      ],
      "metadata": {
        "id": "jUvFYC17Bi5q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hint\n",
        "\n",
        "*   You can use cv2.cornerHarris in opencv.\n",
        "*   For visualization, you can use cv2.line, cv2.circle or any other helper functions in opencv or matplotlib.\n"
      ],
      "metadata": {
        "id": "5JB8fYJCBI6B"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Part 2: Image stitching (30 points)"
      ],
      "metadata": {
        "id": "QE_F4Hf5jUif"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src=\"https://drive.google.com/uc?id=1uOI8rpqb_FsR9Fi8GrGPZvICOcgflBj9&export=download\" width=\"800\"/>\n",
        "\n",
        "## Overview\n",
        "\n",
        "In this problem, you will implement an algorithm for automatically estimating the fundamental matrix F using RANSAC and the normalized 8-point algorithm. \n",
        "\n",
        "Image Stitching Algorithm Overview\n",
        "1. Detect keypoints\n",
        "2. Match keypoints\n",
        "3. Estimate homography with matched keypoints (using RANSAC)\n",
        "4. Combine images\n",
        "\n",
        "**Note:**  Do not use existing image stitching code, such as found on the web, and OpenCV."
      ],
      "metadata": {
        "id": "qSpCKlC_jcde"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data\n",
        "\n",
        "**WARNING: Colab deletes all files everytime runtime is disconnected. Make sure to re-download the inputs when it happens.**"
      ],
      "metadata": {
        "id": "_EOoxrZurmYz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Download Data -- run this cell only one time per runtime\n",
        "!gdown 1fnD0hJ8-_Rngsc-m96ghKtdZAMf0VTjy\n",
        "!unzip \"/content/hill.zip\" -d \"/content/hill\"\n",
        "\n",
        "!gdown 1v2BFVMV0McuD5BstLvDmo1U9MrFAByS5\n",
        "!unzip \"/content/tv.zip\" -d \"/content/tv\"\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tspp6CyMroUC",
        "outputId": "8eb6594d-ba68-44ae-d030-c0bb480016e0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1fnD0hJ8-_Rngsc-m96ghKtdZAMf0VTjy\n",
            "To: /content/hill.zip\n",
            "\r  0% 0.00/205k [00:00<?, ?B/s]\r100% 205k/205k [00:00<00:00, 101MB/s]\n",
            "Archive:  /content/hill.zip\n",
            "  inflating: /content/hill/1.JPG     \n",
            "  inflating: /content/hill/2.JPG     \n",
            "  inflating: /content/hill/3.JPG     \n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1v2BFVMV0McuD5BstLvDmo1U9MrFAByS5\n",
            "To: /content/tv.zip\n",
            "100% 130k/130k [00:00<00:00, 62.5MB/s]\n",
            "Archive:  /content/tv.zip\n",
            "  inflating: /content/tv/1.jpg       \n",
            "  inflating: /content/tv/2.jpg       \n",
            "  inflating: /content/tv/3.jpg       \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Helper Functions"
      ],
      "metadata": {
        "id": "YlVZP1tvMAxH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "\n",
        "def drawMatches(image1, kp1, image2, kp2, idx_pairs):\n",
        "    keypt1 = [cv2.KeyPoint(coord[1], coord[0], 40) for coord in kp1.tolist()]\n",
        "    keypt2 = [cv2.KeyPoint(coord[1], coord[0], 40) for coord in kp2.tolist()]\n",
        "    matches = [cv2.DMatch(pair[0], pair[1], 0) for pair in idx_pairs.tolist()]\n",
        "    return cv2.drawMatches(image1, keypt1, image2, keypt2, matches, None, flags=cv2.DrawMatchesFlags_NOT_DRAW_SINGLE_POINTS)\n",
        "\n",
        "def plot_matches(images, feature_coord, matches, img_idx):\n",
        "    matched_img = drawMatches(images[img_idx], feature_coord[img_idx], images[img_idx-1], \n",
        "                              feature_coord[img_idx-1], matches[img_idx-1])\n",
        "\n",
        "    cv2.imshow('Matches Found', matched_img)\n",
        "    cv2.waitKey(0)\n",
        "    cv2.destroyAllWindows()\n",
        "\n",
        "def est_homography(src, dest):\n",
        "    N = src.shape[0]\n",
        "    if N != dest.shape[0]:\n",
        "        raise ValueError(\"src and diff should have the same dimension\")\n",
        "    src_h = np.hstack((src, np.ones((N, 1))))\n",
        "    A = np.array([np.block([[src_h[n], np.zeros(3), -dest[n, 0] * src_h[n]],\n",
        "                            [np.zeros(3), src_h[n], -dest[n, 1] * src_h[n]]])\n",
        "                  for n in range(N)]).reshape(2 * N, 9)\n",
        "    [_, _, V] = np.linalg.svd(A)\n",
        "    return V.T[:, 8].reshape(3, 3)\n",
        "\n",
        "def apply_homography(H, src):\n",
        "    src_h = np.hstack((src, np.ones((src.shape[0], 1))))\n",
        "    dest =  src_h @ H.T\n",
        "    return (dest / dest[:,[2]])[:,0:2]"
      ],
      "metadata": {
        "id": "y9gRD27_MCDo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Code (15 pt)"
      ],
      "metadata": {
        "id": "YBhvHlseN_6F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# YOUR CODE HERE: "
      ],
      "metadata": {
        "id": "OBO9BLc_-EWG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Write-up (15 pt)\n",
        "*  Describe how to remove incorrect matches with RANSAC \n",
        "*  Display the best homography H after RANSAC \n",
        "*  Display the blended images"
      ],
      "metadata": {
        "id": "gCSoLSQON2yj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hint\n",
        "\n",
        "\n",
        "*   Use Harris Corner Detection to find keypoint. You can use cv2.cornerHarris in opencv.\n",
        "*   For image warping and blending, you should first deterimne canvas size. You can use cv2.warpPerspective in opencv. \n"
      ],
      "metadata": {
        "id": "EGGINt3MCKK6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Part 3: Affine Structure from Motion (40 points)"
      ],
      "metadata": {
        "id": "NVJf6O25JW2k"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Overview\n",
        "<img src=\"https://drive.google.com/uc?id=1nYd0eJjBtVIPuapfxuiVzswjswGN_Gq2&export=download\" width=\"800\"/>\n",
        "\n",
        "\n",
        "This problem continues the interest point detection and tracking problem from HW2. Now, you will recover a 3D pointcloud from the image sequence hotel.seq0.png … hotel.seq50.png. You are encouraged to use your results from HW2, but in case you were not able to complete it, we have also included pre- computed intermediate results in the supplemental material. Submit your code so that we can reproduce your results.\n",
        "\n",
        "The outline of the affine structure from motion algorithm:\n",
        "\n",
        "<img src=\"https://drive.google.com/uc?id=1BSvHwRR5gNBwDGlrk-dcLCRcuIAvab__&export=download\" width=\"700\"/>\n"
      ],
      "metadata": {
        "id": "SGgP6ygcJaqW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data\n",
        "\n",
        "**WARNING: Colab deletes all files everytime runtime is disconnected. Make sure to re-download the inputs when it happens.**"
      ],
      "metadata": {
        "id": "YEdG0AQNK2DN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Download Data -- run this cell only one time per runtime\n",
        "!gdown 1A0Rin_YMmWkExjI99vfLYvU_dy-9gFTT\n",
        "!unzip \"/content/Part2_data.zip\" -d \"/content/\"\n",
        "# Load Matches\n",
        "data = loadmat('/content/Part2_data/tracks.mat')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R0c9I8joK4bW",
        "outputId": "0640dae8-5869-4921-e94a-b801b89ffed9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1A0Rin_YMmWkExjI99vfLYvU_dy-9gFTT\n",
            "To: /content/Part2_data.zip\n",
            "\r  0% 0.00/5.44M [00:00<?, ?B/s]\r100% 5.44M/5.44M [00:00<00:00, 59.5MB/s]\n",
            "Archive:  /content/Part2_data.zip\n",
            "   creating: /content/Part2_data/\n",
            "   creating: /content/Part2_data/images/\n",
            "  inflating: /content/Part2_data/images/hotel.seq0.png  \n",
            "  inflating: /content/Part2_data/images/hotel.seq1.png  \n",
            "  inflating: /content/Part2_data/images/hotel.seq10.png  \n",
            "  inflating: /content/Part2_data/images/hotel.seq11.png  \n",
            "  inflating: /content/Part2_data/images/hotel.seq12.png  \n",
            "  inflating: /content/Part2_data/images/hotel.seq13.png  \n",
            "  inflating: /content/Part2_data/images/hotel.seq14.png  \n",
            "  inflating: /content/Part2_data/images/hotel.seq15.png  \n",
            "  inflating: /content/Part2_data/images/hotel.seq16.png  \n",
            "  inflating: /content/Part2_data/images/hotel.seq17.png  \n",
            "  inflating: /content/Part2_data/images/hotel.seq18.png  \n",
            "  inflating: /content/Part2_data/images/hotel.seq19.png  \n",
            "  inflating: /content/Part2_data/images/hotel.seq2.png  \n",
            "  inflating: /content/Part2_data/images/hotel.seq20.png  \n",
            "  inflating: /content/Part2_data/images/hotel.seq21.png  \n",
            "  inflating: /content/Part2_data/images/hotel.seq22.png  \n",
            "  inflating: /content/Part2_data/images/hotel.seq23.png  \n",
            "  inflating: /content/Part2_data/images/hotel.seq24.png  \n",
            "  inflating: /content/Part2_data/images/hotel.seq25.png  \n",
            "  inflating: /content/Part2_data/images/hotel.seq26.png  \n",
            "  inflating: /content/Part2_data/images/hotel.seq27.png  \n",
            "  inflating: /content/Part2_data/images/hotel.seq28.png  \n",
            "  inflating: /content/Part2_data/images/hotel.seq29.png  \n",
            "  inflating: /content/Part2_data/images/hotel.seq3.png  \n",
            "  inflating: /content/Part2_data/images/hotel.seq30.png  \n",
            "  inflating: /content/Part2_data/images/hotel.seq31.png  \n",
            "  inflating: /content/Part2_data/images/hotel.seq32.png  \n",
            "  inflating: /content/Part2_data/images/hotel.seq33.png  \n",
            "  inflating: /content/Part2_data/images/hotel.seq34.png  \n",
            "  inflating: /content/Part2_data/images/hotel.seq35.png  \n",
            "  inflating: /content/Part2_data/images/hotel.seq36.png  \n",
            "  inflating: /content/Part2_data/images/hotel.seq37.png  \n",
            "  inflating: /content/Part2_data/images/hotel.seq38.png  \n",
            "  inflating: /content/Part2_data/images/hotel.seq39.png  \n",
            "  inflating: /content/Part2_data/images/hotel.seq4.png  \n",
            "  inflating: /content/Part2_data/images/hotel.seq40.png  \n",
            "  inflating: /content/Part2_data/images/hotel.seq41.png  \n",
            "  inflating: /content/Part2_data/images/hotel.seq42.png  \n",
            "  inflating: /content/Part2_data/images/hotel.seq43.png  \n",
            "  inflating: /content/Part2_data/images/hotel.seq44.png  \n",
            "  inflating: /content/Part2_data/images/hotel.seq45.png  \n",
            "  inflating: /content/Part2_data/images/hotel.seq46.png  \n",
            "  inflating: /content/Part2_data/images/hotel.seq47.png  \n",
            "  inflating: /content/Part2_data/images/hotel.seq48.png  \n",
            "  inflating: /content/Part2_data/images/hotel.seq49.png  \n",
            "  inflating: /content/Part2_data/images/hotel.seq5.png  \n",
            "  inflating: /content/Part2_data/images/hotel.seq50.png  \n",
            "  inflating: /content/Part2_data/images/hotel.seq6.png  \n",
            "  inflating: /content/Part2_data/images/hotel.seq7.png  \n",
            "  inflating: /content/Part2_data/images/hotel.seq8.png  \n",
            "  inflating: /content/Part2_data/images/hotel.seq9.png  \n",
            "  inflating: /content/Part2_data/tracks.mat  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Code (20 pt)"
      ],
      "metadata": {
        "id": "VzZskEHdNaxT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "track_x = data['track_x']\n",
        "track_y = data['track_y']\n",
        "\n",
        "# Remove the nan value\n",
        "# YOUR CODE HERE\n",
        "\n",
        "def affineSFM(x, y):\n",
        "  '''\n",
        "  Function: Affine structure from motion algorithm\n",
        "  % Normalize x, y to zero mean\n",
        "  % Create measurement matrix\n",
        "  D = [xn' ; yn'];\n",
        "  % Decompose and enforce rank 3\n",
        "  % Apply orthographic constraints\n",
        "  '''\n",
        "  # YOUR CODE HERE\n",
        "  return None"
      ],
      "metadata": {
        "id": "Mo14ELnGNbIr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Write-up (20 pt)\n",
        "\n",
        "\n",
        "*   Plot the predicted 3D locations of the tracked points for 3 different viewpoints. Choose the viewpoints so that the 3D structure is clearly visible.\n",
        "*   Plot the predicted 3D path of the cameras. The camera position for each frame is given by the cross product a_k = a_i x a_j. Normalize a_k to be unit length for consistent results. Give 3 plots, one for each dimension of a_k \n",
        "<!-- We provide the function plotSfM.m for visualizing the recovered 3D shape and camera positions in each frame. -->\n"
      ],
      "metadata": {
        "id": "wZgGQcmAJhVQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hint\n",
        "\n",
        "\n",
        "*   Do not use existing structure from motion code, such as found in OpenCV.\n",
        "*   The provided file tracks.mat contains the tracked keypoints over 51 frames.viewpoints. \n",
        "*   Reference: \n",
        "    - Tomasi and Kanade. Shape and Motion from Image Streams under Orthography: a Factorization Method. 1992"
      ],
      "metadata": {
        "id": "vtJ465J8KYid"
      }
    }
  ]
}